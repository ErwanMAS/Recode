#!/usr/bin/python
#                                                    -*- coding: latin-1 -*-
# Automatically derive `recode' table files from various sources.
# Copyright © 1993, 1994, 1997, 1998, 1999 Free Software Foundation, Inc.
# François Pinard <pinard@iro.umontreal.ca>, 1993.

# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2, or (at your option)
# any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software Foundation,
# Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.

"""\
`tables.py' derives `recode' table files from various sources.

Usage: python tables.py [OPTION]... DATA-FILE...

  -e  produce C source file for explode data (explode.c)
  -m  produce inclusion file for short mnemonics (rfc1345.h)
  -n  produce inclusion file for character names (charname.h)
  -p  produce C source files for strip data (strip-pool.c and strip-data.c)
  -t  produce inclusion file for Texinfo (charset.texi)
  -F  produce French versions for -n or -t

DATA-FILEs may be rfc1345.txt, mnemonic[.,]ds, Unicode maps, or .def files
from Keld's chset* packages.  The digesting order is usually important.
When `-F' and `-n' are used, process Alain's tables.
"""

import re, string, sys

# Generated file names.
CHARNAME = 'charname.h'
MNEMONIC = 'rfc1345.h'
EXPLODE = 'explode.c'
POOL = 'strip-pool.c'
DATA = 'strip-data.c'
TEXINFO = 'charset.texi'

# Generated copyright clause.
OVERALL_HEADER = """\
/* DO NOT MODIFY THIS FILE!  It was generated by `recode/doc/tables.py'.  */

/* Conversion of files between different charsets and surfaces.
   Copyright © 1999 Free Software Foundation, Inc.
   This file is part of the GNU C Library.
   Contributed by François Pinard <pinard@iro.umontreal.ca>, 1993, 1997.

   The `recode' Library is free software; you can redistribute it and/or
   modify it under the terms of the GNU Library General Public License
   as published by the Free Software Foundation; either version 2 of the
   License, or (at your option) any later version.

   The `recode' Library is distributed in the hope that it will be
   useful, but WITHOUT ANY WARRANTY; without even the implied warranty
   of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   Library General Public License for more details.

   You should have received a copy of the GNU Library General Public
   License along with the `recode' Library; see the file `COPYING.LIB'.
   If not, write to the Free Software Foundation, Inc., 59 Temple Place -
   Suite 330, Boston, MA 02111-1307, USA.  */
"""

# Ignore any mnemonic whose length is greater than MAX_MNEMONIC_LENGTH.
MAX_MNEMONIC_LENGTH = 3

# Character constants.
REPLACEMENT_CHARACTER = 0xFFFD
NOT_A_CHARACTER = 0xFFFF

# Change STRIP_SIZE in `src/recode.h' if you change the value here.
# See the accompanying documentation there, as needed.
STRIP_SIZE = 8

# Main driver.

def warn(format, *args):
    sys.stderr.write('%s:%s: %s\n' % (input_name, line_count, format % args))

def die(format, *args):
    sys.stderr.write('%s:%s: %s\n' % (input_name, line_count, format % args))
    raise 'Fatal'

def main(*arguments):
    global input_name
    global line_count
    global input

    global alias_count
    global charset_ordinal
    global comment
    global discard_charset

    global charname_option
    global explode_option
    global mnemonic_option
    global strip_option
    global texinfo_option

    import getopt

    # Argument decoding.
    French_option = 0
    charname_option = 0
    explode_option = 0
    mnemonic_option = 0
    strip_option = 0
    texinfo_option = 0
    options, arguments = getopt.getopt(arguments, 'Femnpt')
    for option, value in options:
        if option == '-F': French_option = 1
        elif option == '-e': explode_option = 1
        elif option == '-m': mnemonic_option = 1
        elif option == '-n': charname_option = 1
        elif option == '-p': strip_option = 1
        elif option == '-t': texinfo_option = 1
    if not arguments:
        raise __doc__

    if explode_option:
        produce_explode_init(EXPLODE)
    elif strip_option:
        produce_strip_init(DATA)

    # Prepare to read various tables.

    charset_ordinal = 0
    discard_charset = 0
    alias_count = 0
    comment = ''

    # Read all data tables.

    for input_name in arguments:
        input = open(input_name)
        line_count = 0
        sys.stderr.write("Reading %s\n" % input_name)
        while 1:
            line = input.readline()
            line_count = line_count + 1
            if not line:
                break
            if re.match('$', line):
                continue

            if re.match('\#    Name:', line):
                digest_unimap()
                break

            if re.match('\#', line):
                continue

            if re.match('escape_char', line):
                digest_mnemonics()
                break

            if re.match('Network Working Group +K\. Simonsen$', line):
                if charname_option and not French_option:
                    while not re.match('   3rd field is the long descriptive',
                                       line):
                        line = input.readline()
                        line_count = line_count + 1
                    digest_rfc1345_names()
                if explode_option or strip_option:
                    while not re.match('5\.  CHARSET TABLES$', line):
                        line = input.readline()
                        line_count = line_count + 1
                    digest_rfc1345_tables()
                break

            if re.match(';Titre :', line):
                if charname_option and French_option:
                    while not re.match('; SOUSCRIT', line):
                        line = input.readline()
                        line_count = line_count + 1
                    while not re.match(' *$', line):
                        line = input.readline()
                        line_count = line_count + 1
                    digest_french_names()
                break

            if re.match('&referenceset$', line):
                while not re.match('$', line):
                    line = input.readline()
                    line_count = line_count + 1
                digest_rfc1345_tables()
                break

            if re.match('   Repertoire according to ISO/IEC 10646-1:1993$',
                        line):
                while not re.match('   Plane 000$', line):
                    line = input.readline()
                    line_count = line_count + 1
                digest_iso10646_def()
                break

            die("Data file with unknown contents")

        input.close()

    if explode_option:
        produce_explode_term(EXPLODE)
    elif strip_option:
        produce_strip_term(DATA, POOL)
    if charname_option:
        if French_option:
            produce_charname('fr-%s' % CHARNAME)
        else:
            produce_charname(CHARNAME)
    if mnemonic_option:
        produce_mnemonic(MNEMONIC)
    if texinfo_option:
        if French_option:
            produce_texinfo('fr-%s' % TEXINFO)
        else:
            produce_texinfo(TEXINFO)

# Data readers.

## ----------------------------------------- ##
## Read in Keld's list of 10646 characters.  ##
## ----------------------------------------- ##

def digest_iso10646_def():
    global line_count
    global row, cell

    while 1:
        line = input.readline()
        line_count = line_count + 1
        if not line:
            break
        if re.match('$', line):
            continue
        if re.match(' $', line):
            continue                    # happens three times
        if re.match('   \.\.\.', line):
            continue
        if re.match('   Presentation forms$', line):
            continue
        if re.match('   naming: first vertical ', line):
            continue

        match = re.match('   row ([0-9][0-9][0-9])$', line)
        if match and int(match.group(1)) < 256:
            row = int(match.group(1))
            cell = 0
            continue

        if re.match('   cell 00$', line):
            cell = 0
            continue

        match = re.match('   cell ([0-9][0-9][0-9])$', line)
        if match and int(match.group(1)) < 256:
            cell = int(match.group(1))
            continue

        match = re.match('   ([^ ]+)', line)
        if match:                       # FIXME: $1 n'a pas de sens!
            # s/^   // unless /^   [A-Z][A-Z][A-Z]/;
            if not re.match('   [A-Z][A-Z][A-Z]', line):
                continue

        match = re.match('   ([^ ].*)', line)
        if match:                       # FIXME: $1 n'a pas de sens!
            if cell == 256:
                warn("Over 256 cells in row %d", row)
            cell = cell + 1
            continue

        match = (re.match('([^ ])  ([^ ].*)', line)
                 or re.match('([^ ][^ ]+) ([^ ].*)', line))
        if match:                       # FIXME: $2 n'a pas de sens!
            if cell == 256:
                warn("Over 256 cells in row %d", row)
            declare_mnemonic(match.group(1), 256*row + cell)
            cell = cell + 1
            continue

        warn("Unrecognised line")

## -------------------------- ##
## Read in a mnemonics file.  ##
## -------------------------- ##

def digest_mnemonics():
    global line_count

    while 1:
        line = input.readline()
        line_count = line_count + 1
        if not line:
            break
        match = re.match('<([^ \t\n]+)>\t<U(....)>', line)
        if match:
            mnemonic = re.sub('/(.)', r'\1', match.group(1))
            ucs2 = string.atoi(match.group(2), 16)
            declare_mnemonic(mnemonic, ucs2)

## ------------------------------------------------------------------- ##
## Read the text of RFC 1345, saving all character names it declares.  ##
## ------------------------------------------------------------------- ##

# Numeric value of a character, given its mnemonic.
ucs2_map = {}

# Name of character, given its numerical value.
charname_map = {}

# Frequency of each word, then its crypt code.
code_map = {}

# Maximum printable length of a character name.
max_length = 0

def digest_rfc1345_names():
    global max_length

    def read_line():
        global line_count

        skip = 0
        while 1:
            line = input.readline()
            line_count = line_count + 1
            if not line:
                break
            if re.match('Simonsen', line):
                skip = 1
                continue
            if skip:
                if re.match('RFC 1345', line):
                    skip = 0
                continue
            if re.match('4.  CHARSETS', line):
                break
            if re.match('$', line):
                continue
            if line[0] == ' ':
                return string.lstrip(line[:-1])
        return None

    max_length = 0

    # Read the character descriptions.  Count words in charnames.

    line = read_line()
    while line:
	# Look ahead one line and merge it if it should.

        next = read_line()
        while next:
            match = re.match('             *( .*)', next)
            if not match:
                break
            line = line + match.group(1)
            next = read_line()

	# Separate fields and save needed information.

        match = re.search('([^ ]+) +[0-9a-f]+ +(.*)', line)
        if match:
            mnemo = match.group(1)
            text = string.lower(match.group(2))

            if ucs2_map.has_key(mnemo):
                charname_map[ucs2_map[mnemo]] = text
                if len(text) > max_length:
                    max_length = len(text)
                for word in string.split(text):
                    if code_map.has_key(word):
                        code_map[word] = code_map[word] + 1
                    else:
                        code_map[word] = 1
            elif len(mnemo) <= MAX_MNEMONIC_LENGTH:
                warn("No known UCS-2 code for `%s'", mnemo)
        elif not re.search(' +e000', line):
            warn("What about `%s'?", line)

        line = next

def digest_french_names():
    global line_count
    global max_length

    max_length = 0
    ucs = 0x0000

    for text in (
        "nul (nul)",                                        # 0000
        "début d'en-tête (soh)",                            # 0001
        "début de texte (stx)",                             # 0002
        "fin de texte (etx)",                               # 0003
        "fin de transmission (eot)",                        # 0004
        "demande (enq)",                                    # 0005
        "accusé de réception positif (ack)",                # 0006
        "sonnerie (bel)",                                   # 0007
        "espace arrière (bs)",                              # 0008
        "tabulation horizontale (ht)",                      # 0009
        "interligne (lf)",                                  # 000A
        "tabulation verticale (vt)",                        # 000B
        "page suivante (ff)",                               # 000C
        "retour de chariot (cr)",                           # 000D
        "hors code (so)",                                   # 000E
        "en code (si)",                                     # 000F
        "échappement transmission (dle)",                   # 0010
        "commande d'appareil un (dc1)",                     # 0011
        "commande d'appareil deux (dc2)",                   # 0012
        "commande d'appareil trois (dc3)",                  # 0013
        "commande d'appareil quatre (dc4)",                 # 0014
        "accusé de réception négatif (nak)",                # 0015
        "synchronisation (syn)",                            # 0016
        "fin de transmission de bloc (etb)",                # 0017
        "annulation (can)",                                 # 0018
        "fin de support (em)",                              # 0019
        "caractère de substitution (sub)",                  # 001A
        "échappement (esc)",                                # 001B
        "séparateur de fichier (fs)",                       # 001C
        "séparateur de groupe (gs)",                        # 001D
        "séparateur d'article (rs)",                        # 001E
        "séparateur de sous-article (us)",                  # 001F
        ):
        charname_map[ucs] = text
        ucs = ucs + 1
        if len(text) > max_length:
            max_length = len(text)
        for word in string.split(text):
            if code_map.has_key(word):
                code_map[word] = code_map[word] + 1
            else:
                code_map[word] = 1

    ucs = 0x007F
    for text in (
        "suppression (del)",                                # 007F
        "caractère de bourre (pad)",                        # 0080
        "octet supérieur prédéfini (hop)",                  # 0081
        "arrêt permis ici (bph)",                           # 0082
        "aucun arrêt ici (nbh)",                            # 0083
        "index (ind)",                                      # 0084
        "à la ligne (nel)",                                 # 0085
        "début de zone sélectionnée (ssa)",                 # 0086
        "fin de zone sélectionnée (esa)",                   # 0087
        "arrêt de tabulateur horizontal (hts)",             # 0088
        "tabulateur horizontal avec justification (htj)",   # 0089
        "arrêt de tabulateur vertical (vts)",               # 008A
        "interligne partiel vers <= bas (pld)",             # 008B
        "interligne partiel vers <= haut (plu)",            # 008C
        "index inversé (ri)",                               # 008D
        "remplacement unique deux (ss2)",                   # 008E
        "remplacement unique trois (ss3)",                  # 008F
        "chaîne de commande d'appareil (dcs)",              # 0090
        "usage privé un (pu1)",                             # 0091
        "usage privé deux (pu2)",                           # 0092
        "mise en mode transmission (sts)",                  # 0093
        "annulation du caractère précédent (cch)",          # 0094
        "message en attente (mw)",                          # 0095
        "début de zone protégée (sga)",                     # 0096
        "fin de zone protégée (ega)",                       # 0097
        "début de chaîne (sos)",                            # 0098
        "introducteur de caractère graphique unique (sgci)",# 0099
        "introducteur de caractère unique (sci)",           # 009A
        "introducteur de séquence de commande (csi)",       # 009B
        "fin de chaîne (st)",                               # 009C
        "commande de système d'exploitation (osc)",         # 009D
        "message privé (pm)",                               # 009E
        "commande de progiciel (apc)",                      # 009F
        ):
        charname_map[ucs] = text
        ucs = ucs + 1
        if len(text) > max_length:
            max_length = len(text)
        for word in string.split(text):
            if code_map.has_key(word):
                code_map[word] = code_map[word] + 1
            else:
                code_map[word] = 1

    fold_table = range(256)
    for before, after in map(None,
                             'ABCDEFGHIJKLMNOPQRSTUVWXYZÀÂÇÈÉÊÎÏÑÔÖÛ',
                             'abcdefghijklmnopqrstuvwxyzàâçèéêîïñôöû'):
        fold_table[ord(before)] = ord(after)
    folding = string.join(map(chr, fold_table), '')

    while 1:
        line = input.readline()
        line_count = line_count + 1
        if not line:
            break
        if line[-1] == '\n':
            line = line[:-1]
        line = string.rstrip(line)
        match = re.match('([0-9A-F]{4}) ([^\(]+)( \(.*\))?$', line)
        if match:
            ucs = string.atoi(match.group(1), 16)
            text = string.translate(match.group(2), folding)

            charname_map[ucs] = re.sub(r' +\*$', '', text, 1)
            if len(match.group(2)) > max_length:
                max_length = len(match.group(2))
            for word in string.split(text):
                if code_map.has_key(word):
                    code_map[word] = code_map[word] + 1
                else:
                    code_map[word] = 1
        else:
            warn("What about `%s'?", line)

## ------------------------------------------------------------ ##
## Read the text of RFC 1345, saving all charsets it declares.  ##
## UCS-2 mnemonics files should have been read in already.      ##
## ------------------------------------------------------------ ##

used_map = {}
table = []

#codedim
#code
#list

declare_alias = []
implied_surface = {}
#hashname

def digest_rfc1345_tables():
    global alias_count
    global aliases
    global charset
    global line_count
    global comment
    global discard_charset
    global remark
    global table

    # Informal canonical order of presentation.
    CHARSET, REM, ALIAS, ESC, BITS, CODE = range(6)

    skip = 0
    while 1:
        line = input.readline()
        line_count = line_count + 1
        if not line:
            break
        if re.match('Simonsen', line):
            skip = 1
            continue
        if skip:
            if re.match('RFC 1345', line):
                skip = 0
            continue
        if re.match('$', line):
            continue
        if re.match('ACKNOWLEDGEMENTS$', line):
            break

        line, count = re.subn('^  ?', '', line)
        if not count:
            continue

	# Recognize `&charset'.

        match = re.match('&charset (.*)', line)
        if match:
	    # Before beginning a new charset, process the previous one.
            complete_charset()
            charset = match.group(1)

	    # Prepare for processing a new charset: save the charset
	    # name for further declaration; announce this charset in
	    # the array initialization section; and initialize its
	    # processing.

            sys.stderr.write("  %d) %s\n" % (charset_ordinal + 1, charset))
            status = CHARSET

            comment = '\n/* %s\n' % charset

            hashname = re.sub('[^a-z0-9]', '', string.lower(charset))
            if used_map.has_key(hashname):
                warn("Duplicate of %s (discarded)", used_map[hashname])
                discard_charset = 1
                continue
            used_map[hashname] = charset

            alias_count = 0
            table = [NOT_A_CHARACTER] * 256
            codedim = 0
            code = 0
            aliases = []
            remark = []

            match = re.match('(CP|IBM)([0-9]+)$', charset)
            if match:
                implied_surface[match.group(2)] = 'crlf'
                implied_surface['CP' + match.group(2)] = 'crlf'
                implied_surface['IBM' + match.group(2)] = 'crlf'
                declare_alias.append((charset, charset))
                alias_count = alias_count + 1
                continue

#FIXME:            match = re.match('windows-([0-9]+)$', charset)
#FIXME:            if match:
#FIXME:                  implied_surface[match.group(1)] = 'crlf'
#FIXME:                  implied_surface['CP' + match.group(1)] = 'crlf'
#FIXME:                  implied_surface['IBM' + match.group(1)] = 'crlf'
#FIXME:                  declare_alias.append((charset, charset))
#FIXME:                  alias_count = alias_count + 1
#FIXME:                  continue

            match = re.match('macintosh(_ce)?$', charset)
            if match:
                implied_surface[charset] = 'cr'
                declare_alias.append((charset, charset))
                alias_count = alias_count + 1
                continue

            continue

	# Recognize other `&' directives.

        match = re.match('&rem (.*)', line)
        if match and not re.match('&rem &alias', line):
	    # Keld now prefers `&rem' to be allowed everywhere.
	    #if status > REM:
	    #    warn("`&rem' out of sequence")
	    #status = REM;

            if texinfo_option:
		# Save remarks for Texinfo.
                text = match.group(1)
                remark.append(text)
            continue

        match = re.match('(&rem )?&alias (.*)', line)
        if match:
            if status > ALIAS:
                warn("`&alias' out of sequence")
            status = ALIAS

	    # Save synonymous charset names for later declarations.

            alias = match.group(2)
            if alias[-1] == ' ':
                warn("Spurious trailing whitespace")
                alias = string.rstrip(alias)
            comment = comment + '   %s\n' % alias

            hashname = re.sub('[^a-z0-9]', '', string.lower(alias))
            if used_map.has_key(hashname) and used_map[hashname] != charset:
                warn("Duplicate of %s", used_map[hashname])
                continue
            used_map[hashname] = charset

            aliases.append(alias)

            match = re.match('(CP|IBM)([0-9]+)$', alias)
            if match:
                implied_surface[match.group(2)] = 'crlf'
                implied_surface['CP' + match.group(2)] = 'crlf'
                implied_surface['IBM' + match.group(2)] = 'crlf'
            elif re.match('mac(ce)?$', alias):
                implied_surface[alias] = 'cr'
            declare_alias.append((alias, charset))
            alias_count = alias_count + 1
            continue

        if re.match('&g[0-4]esc', line):
            if status > ESC:
                warn("`&esc' out of sequence")
            status = ESC
            continue

        match = re.match('&bits ([0-9]+)$', line)
        if match:
            if status > BITS:
                warn("`&bits' out of sequence")
            status = BITS

            if int(match.group(1)) > 8:
                warn("`&bits %s' not accepted (charset discarded)",
                     match.group(1))
                discard_charset = 1
            continue

        match = re.match('&code (.*)', line)
        if match:
            if status > CODE:
                warn("`&code' out of sequence")
            status = CODE

	    # Save the code position.

            code = int(match.group(1))
            continue

	# Other lines cause the charset to be discarded.

        match = re.match('&([^ ]+)', line)
        if match:
            if not discard_charset:
                warn("`&%s' not accepted (charset discarded)", match.group(1))
                discard_charset = 1

        if discard_charset:
            continue

	# Save all other tokens into the double table.

        if explode_option or strip_option:
            for token in string.split(line):
                if token == '??':
                    table[code] = NOT_A_CHARACTER
                elif token == '__':
                    table[code] = REPLACEMENT_CHARACTER
                elif ucs2_map.has_key(token):
                    table[code] = ucs2_map[token]
                    if len(token) > codedim:
                        codedim = len(token)
                else:
                    warn("Unknown mnemonic for code: %s", token)
                    table[code] = REPLACEMENT_CHARACTER
                code = code + 1

    # Push the last charset out.
    complete_charset()

## ---------------------------------------------------------------- ##
## Read a Unicode map, as found in ftp://ftp.unicode.com/MAPPINGS.  ##
## ---------------------------------------------------------------- ##

def digest_unimap():
    global alias_count
    global aliases
    global charset
    global comment
    global discard_charset
    global line_count
    global remark
    global table

    match = re.match('# +Name: +([^ ]+) to Unicode table$', line)
    if match:
        name = string.split(match.group(1))
        charset = name[0]
        del name[0]
        comment = '\n/* %s\n' % charset

        hashname = re.sub('[^a-z0-9]', '', string.lower(charset))
        if used_map[hashname]:
            warn("`%s' duplicates `%s' (charset discarded)",
                 hashname, used_map[hashname])
            discard_charset = 1
            return
        used_map[hashname] = charset

        alias_count = 0
        table = [NOT_A_CHARACTER] * 256
        codedim = 0
        code = 0
        aliases = []
        remark = []
    if discard_charset:
        return

    for alias in name:
        comment = comment + '   %s\n' % alias

        hashname = re.sub('[^a-z0-9]', '', string.lower(alias))
        if used_map[hashname] and used_map[hashname] != charset:
            warn("`%s' duplicates `%s'", hashname, used_map[hashname])
            continue
        used_map[hashname] = charset

        aliases.append(alias)
        declare_alias.append((alias, charset))
        alias_count = alias_count + 1

    while 1:
        line = input.readline()
        line_count = line_count + 1
        if not line:
            break
        if re.match('$', line):
            continue
        if re.match('#', line):
            continue
        if re.match('0x([0-9A-F]+)\t\t#UNDEFINED$', line):
            continue
        if re.search('\032', line):
            # Old MS-DOS C-z !!
            break

        match = re.match('0x([0-9A-F]+)\t0x([0-9A-F]+)\t\#', line)
        if match:
            table[string.atoi(match.group(1), 16)] \
                                              = string.atoi(match.group(2), 16)
        else:
            warn("Unrecognised input line")

    complete_charset()

# Reader services.

## ---------------------------------------------------------------- ##
## Declare a correspondence between a mnemonic and an UCS-2 value.  ##
## ---------------------------------------------------------------- ##

table_length = 0
mnemonic_map = {}

def declare_mnemonic(mnemonic, ucs2):
    global table_length

    if len(mnemonic) > MAX_MNEMONIC_LENGTH:
        return

    if mnemonic_option:
        if mnemonic_map.has_key(ucs2):
            if mnemonic_map[ucs2] != mnemonic:
                warn("U+%04X `%s' known as `%s'",
                     ucs2, mnemonic, mnemonic_map[ucs2])
                if len(mnemonic) < len(mnemonic_map[ucs2]):
                    mnemonic_map[ucs2] = mnemonic

        else:
            mnemonic_map[ucs2] = mnemonic
            table_length = table_length + 1

    if charname_option or explode_option or strip_option:
        if ucs2_map.has_key(mnemonic):
            if ucs2_map[mnemonic] != ucs2:
                warn("`%s' U+%04X known as U+%04X",
                     mnemonic, ucs2, ucs2_map[mnemonic])
                #FIXME: ??? cell = ucs2_map[mnemonic] - 256*row
        else:
            ucs2_map[mnemonic] = ucs2

## ---------------------------------------------------------- ##
## Print all accumulated information for the charset.  If the ##
## charset should be discarded, adjust tables.                ##
## ---------------------------------------------------------- ##

aliases_map = {}
remark_map = {}
declare_charset = []

def complete_charset():
    global alias_count
    global charset_ordinal
    global comment
    global discard_charset

    if discard_charset:
        while alias_count > 0:
            del declare_alias[-1]
            alias_count = alias_count - 1
        discard_charset = 0
        comment = ''
    if not comment:
        return

    if texinfo_option:

	# Save the documentation.
        aliases.sort()
        aliases_map[charset] = aliases
        remark_map[charset] = remark

    if explode_option:
        write = output.write

	# Make introductory C comments.
        write(comment)
        write('*/\n')

	# Make the table for this charset.
        write('\n')
        write('static const unsigned short data_%d[] =\n' % charset_ordinal)
        write('  {\n')
        for code in range(256):
            if code != table[code]:
                write('    %3d, 0x%.4X, DONE,\n' % (code, table[code]))
        write('    DONE\n')
        write('  };\n')

	# Register the table.
        declare_charset.append(charset)

    if strip_option:
        write = output.write

	# Make introductory C comments.
        write(comment)
        write('*/\n')

	# Make the table for this charset.
        write('\n')
        write('static struct strip_data data_%d =\n' % charset_ordinal)
        write('  {\n')
        write('    ucs2_data_pool,\n')
        write('    {\n')
        count = 0
        for code in range(0, 256, STRIP_SIZE):
            if count % 12 == 0:
                if count != 0:
                    write(',\n')
                write('      ')
            else:
                write(', ')
            write('%4d' % pool_index(table[code:code+STRIP_SIZE]))
            count = count + 1
        write('\n')
        write('    }\n')
        write('  };\n')

	# Register the table.
        declare_charset.append(charset)

    charset_ordinal = charset_ordinal + 1
    comment = ''

## --------------------------------------------------------------- ##
## Return the pool index for strip.  Add to the pool as required.  ##
## --------------------------------------------------------------- ##

def pool_index(strip):
    global strips
    global pool_refs
    global pool_size

    def format(item):
        return '%04X' % item

    pool_refs = pool_refs + 1
    text = string.join (map(format, strip), '')
    if not strip_map.has_key(text):
        strip_map[text] = pool_size
        pool_size = pool_size + STRIP_SIZE
        strips.append(text)
    return strip_map[text]

# Table writers.

## -------------------------------------------- ##
## Write a compressed list of character names.  ##
## -------------------------------------------- ##

def produce_charname(output_name):
    global output

    output = open(output_name, 'w')
    sys.stderr.write("Writing %s\n" % output_name)

    write = output.write
    write(OVERALL_HEADER)

    # Establish a mild compression scheme.  Words word[0:singles] will be
    # represented by a single byte running from 1 to singles.  All remaining
    # words will be represented by two bytes, the first one running slowly
    # from singles+1 to 255, the second cycling faster from 1 to 255.

    def presort_word(word):
        return -code_map[word], word

    def postsort_word(pair):
        return pair[1]

    sys.stderr.write('  sorting words...')
    pairs = map(presort_word, code_map.keys())
    pairs.sort()
    words = map(postsort_word, pairs)
    pairs = None
    sys.stderr.write(' %d of them\n' % len(words))

    count = len(words)
    singles = (255 * 255 - count) / 254

    # Transmit a few values for further usage by the C code.

    sys.stderr.write('  sorting names...')
    ucs2_table = charname_map.keys()
    ucs2_table.sort()
    sys.stderr.write(' %d of them\n' % len(ucs2_table))

    write('\n')
    write('#define NUMBER_OF_SINGLES %d\n' % singles)
    write('#define MAX_CHARNAME_LENGTH %d\n' % max_length)
    write('#define NUMBER_OF_CHARNAMES %d\n' % len(ucs2_table))

    # Establish a mild compression scheme (one or two bytes per word).

    sys.stderr.write("  writing words\n")
    write('\n')
    write('static const char *const word[%d] =\n' % count)
    write('  {\n')

    char1 = 1
    char2 = 1

    for counter in range(singles):
        word = words[counter]
        write('    %-28s/* \\%0.3o */\n'
              % ('"%s",' % re.sub('"', r'\"', word), char1))
        code_map[words[counter]] = char1
        char1 = char1 + 1

    for counter in range(singles, count):
        word = words[counter]
        write('    %-28s/* \\%0.3o\\%0.3o */\n'
              % ('"%s",' % re.sub('"', r'\"', word, 1), char1, char2))
        code_map[words[counter]] = 256 * char1 + char2
        if char2 == 255:
            char1 = char1 + 1
            char2 = 1
        else:
            char2 = char2 + 1
    write('  };\n')

    sys.stderr.write("  writing names\n")
    write('\n')
    write('struct charname\n')
    write('  {\n')
    write('    recode_ucs2 code;\n')
    write('    const char *crypted;\n')
    write('  };\n')

    write('\n')
    write('static const struct charname charname[NUMBER_OF_CHARNAMES] =\n')
    write('  {\n')

    for ucs2 in ucs2_table:
        write('    {0x%04X, "' % ucs2)
        for word in string.split(charname_map[ucs2]):
            if code_map.has_key(word):
                code = code_map[word]
                if code < 256:
                    write('\\%0.3o' % code)
                else:
                    write('\\%0.3o\\%0.3o' % (code / 256, code % 256))
            else:
                sys.stderr.write('??? %s\n' % word)
        write('"},\n')

    write('  };\n')
    output.close()

## ------------------------------------------- ##
## Write an UCS-2 to RFC 1345 mnemonic table.  ##
## ------------------------------------------- ##

def produce_mnemonic(output_name):
    global output

    inverse_map = {}

    output = open(output_name, 'w')
    sys.stderr.write("Writing %s\n" % output_name)

    write = output.write
    write(OVERALL_HEADER)
    write('\n')
    write('#define TABLE_LENGTH %d\n' % table_length)
    write('#define MAX_MNEMONIC_LENGTH %d\n' % MAX_MNEMONIC_LENGTH)
    write('\n')
    write('struct entry\n')
    write('  {\n')
    write('    recode_ucs2 code;\n')
    write('    const char *rfc1345;\n')
    write('  };\n')

    write('\n')
    write('static const struct entry table[TABLE_LENGTH] =\n')
    write('  {\n')
    count = 0
    indices = mnemonic_map.keys()
    indices.sort()
    for ucs2 in indices:
        text = mnemonic_map[ucs2]
        inverse_map[text] = count
        write('    /* %4d */ {0x%04X, "%s"},\n'
              % (count, ucs2, re.sub(r'([\"])', r'\\\1', text)))
        count = count + 1
    write('  };\n')

    write('\n')
    write('static const unsigned short inverse[TABLE_LENGTH] =\n')
    write('  {')
    count = 0
    keys = inverse_map.keys()
    keys.sort()
    for text in keys:
        if count % 10 == 0:
            if count != 0:
                write(',')
            write('\n    /* %4d */ ' % count)
        else:
            write(', ')
        write('%4d' % inverse_map[text])
        count = count + 1
    write('\n')
    write('  };\n')

    output.close()

## ------------------------------- ##
## Write the explode source file.  ##
## ------------------------------- ##

def produce_explode_init(output_name):
    global output

    # Prepare the production of tables.
    output = open(output_name, 'w')
    sys.stderr.write("Starting %s\n" % output_name)

    write = output.write
    write(OVERALL_HEADER)

    write('\n')
    write('#include "common.h"\n')

    # Table fragments will be produced while reading data tables.

def produce_explode_term(output_name):

    # Print the collectable initialization function.
    sys.stderr.write("Completing %s\n" % output_name)

    write = output.write
    write('\n')
    write('bool\n')
    write('module_explodes (struct recode_outer *outer)\n')
    write('{\n')
    count = 0
    while declare_charset:
        write('  if (!declare_explode_data (outer, &data_%d, "%s"))\n'
              % (count, declare_charset[0]))
        write('    return false;\n')
        del declare_charset[0]
        count = count + 1
    write('\n')
    while declare_alias:
	write('  if (!declare_alias (outer, "%s", "%s"))\n' % declare_alias[0])
        write('    return false;\n')
        del declare_alias[0]
    write('\n')
    write('  return true;\n')
    write('}\n')

    output.close()

## --------------------------------- ##
## Write the pool and index tables.  ##
## --------------------------------- ##

def produce_strip_init(output_name):
    global output
    global pool_refs
    global pool_size
    global strips
    global strip_map

    # Prepare the production of tables.
    pool_size = 0
    pool_refs = 0
    strip_map = {}
    strips = []

    output = open(output_name, 'w')
    sys.stderr.write("Starting %s\n" % output_name)

    write = output.write
    write(OVERALL_HEADER)
    write('\n')
    write('#include \"common.h\"\n')

    # Table fragments will be produced while reading data tables.

def produce_strip_term(output_name, pool_name):
    global output

    # Give memory statistics.
    sys.stderr.write('Table memory = %d bytes (pool %d, refs %d)\n'
                     % (pool_size * 2 + pool_refs * 2,
                        pool_size * 2,
                        pool_refs * 2))

    # Print the collectable initialization function.
    sys.stderr.write("Completing %s\n" % output_name)
    write = output.write

    write('\n')
    write('bool\n')
    write('module_strips (struct recode_outer *outer)\n')
    write('{\n')
    write('  RECODE_SYMBOL symbol;\n')
    write('\n')
    count = 0
    while declare_charset:
        write('  if (!declare_strip_data (outer, &data_%d, "%s"))\n'
              % (count, declare_charset[0]))
        write('    return false;\n')
        del declare_charset[0]
        count = count + 1
    write('\n')
    while declare_alias:
        alias, charset = declare_alias[0]
        if implied_surface.has_key(alias):
            write('  if (symbol = declare_alias (outer, "%s", "%s"), !symbol)\n'
                  % declare_alias[0])
	    write('    return false;\n')
	    write('  if (!declare_implied_surface (outer, symbol, outer->%s_surface))\n'
                  % implied_surface[alias])
	    write('    return false;\n')
        else:
	    write('  if (!declare_alias (outer, "%s", "%s"))\n'
                  % declare_alias[0])
	    write('    return false;\n')
        del declare_alias[0]
    write('\n')
    write('  return true;\n')
    write('}\n')

    output.close()

    # Write the pool file.

    output = open(pool_name, 'w')
    sys.stderr.write("Writing %s\n" % pool_name)

    write = output.write
    write(OVERALL_HEADER)
    write('\n')
    write('#include \"common.h\"\n')
    write('\n')
    write('const recode_ucs2 ucs2_data_pool[%d] =\n' % pool_size)
    write('  {')
    count = 0
    for strip in strips:
        for pos in range(0, STRIP_SIZE * 4, 4):
            if count % 8 == 0:
                if count != 0:
                    write(',')
                write('\n    /* %4d */ ' % count)
            else:
                write(', ')
            write('0x' + strip[pos:pos+4])
            count = count + 1
    write('\n')
    write('  };\n')

    output.close()

## ------------------------------ ##
## Write the documentation file.  ##
## ------------------------------ ##

def produce_texinfo(output_name):
    global output

    output = open(output_name, 'w')
    sys.stderr.write("Writing %s\n" % output_name)
    write = output.write

    charsets = remark_map.keys()
    charsets.sort()
    for charset in charsets:
        write('\n@item %s\n' % charset)
	write('@tindex %s@r{, aliases and source}\n' % charset)
        aliases = aliases_map[charset]
        if aliases:
            if len(aliases) == 1:
                if aliases[0]:                # FIXME: pourquoi parfois vide ??
                    write('@tindex %s\n' % aliases[0])
                    write('@code{%s} is an alias for this charset.\n'
                          % aliases[0])
            else:
                for alias in aliases:
                    write('@tindex %s\n' % alias)
                write('@code{%s} and @code{%s} are aliases for this charset.\n'
                      % (string.join(aliases[:-1], '}, @code{'), aliases[-1]))
        for line in remark_map[charset]:
            match = re.match('([a-z])(.*)', line)
            if match:
                line = string.upper(match.group(1)) + match.group(2)
            write(re.sub('@', '@@', line))
            if line[-1] != '.':
                write('.')
            write('\n')

    output.close()

if __name__ == '__main__':
    apply(main, tuple(sys.argv[1:]))
