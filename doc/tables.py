#!/usr/bin/python
#                                                    -*- coding: latin-1 -*-
# Automatically derive `recode' table files from various sources.
# Copyright © 1993, 1994, 1997, 1998, 1999 Free Software Foundation, Inc.
# François Pinard <pinard@iro.umontreal.ca>, 1993.

# This program is free software; you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation; either version 2, or (at your option)
# any later version.

# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.

# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software Foundation,
# Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.

"""\
`tables.py' derives `recode' table files from various sources.

Usage: python tables.py [OPTION]... DATA-FILE...

  -e  produce C source file for explode data (explode.c)
  -l  produce C source file for libiconv charsets (libiconv.h)
  -m  produce C inclusion file for short RFC 1345 mnemonics (rfc1345.h)
  -n  produce C inclusion file for character names (charname.h)
  -p  produce C source files for strip data (strip-pool.c and strip-data.c)
  -s  produce Texinfo inclusion file for libiconv (libiconv.texi)
  -t  produce Texinfo inclusion file for RFC 1345 (rfc1345.texi)
  -F  produce French versions for -n, -s or -t

DATA-FILEs may be rfc1345.txt, mnemonic[.,]ds, Unicode maps, or .def files
from Keld's chset* packages.  The digesting order is usually important.
When `-F' and `-n' are used, process Alain's tables.
"""

import re, string, sys

# Generated file names.
CHARNAME = 'charname.h'
EXPLODE = 'explode.c'
LIBICONV = 'libiconv.h'
POOL = 'strip-pool.c'
DATA = 'strip-data.c'
LIBICONV_TEXINFO = 'libiconv.texi'
RFC1345_MNEMONIC = 'rfc1345.h'
RFC1345_TEXINFO = 'rfc1345.texi'

# Ignore any mnemonic whose length is greater than MAX_MNEMONIC_LENGTH.
MAX_MNEMONIC_LENGTH = 3

# Character constants.
REPLACEMENT_CHARACTER = 0xFFFD
NOT_A_CHARACTER = 0xFFFF

# Change STRIP_SIZE in `src/recode.h' if you change the value here.
# See the accompanying documentation there, as needed.
STRIP_SIZE = 8

# Handling basic input and output.

class Input:

    def __init__(self, name):
        self.name = name
        self.input = open(name)
        self.line_count = 0
        sys.stderr.write("Reading %s\n" % name)

    def readline(self):
        self.line = self.input.readline()
        self.line_count = self.line_count + 1
        return self.line

    def warn(self, format, *args):
        sys.stderr.write('%s:%s: %s\n'
                         % (self.name, self.line_count, format % args))

    def die(self, format, *args):
        sys.stderr.write('%s:%s: %s\n'
                         % (self.name, self.line_count, format % args))
        raise 'Fatal'

    def begins(self, text):
        return self.line[:len(text)] == text

    def match(self, pattern):
        return re.match(pattern, self.line)

    def search(self, pattern):
        return re.search(pattern, self.line)

class Output:

    def __init__(self, name, noheader=0):
        self.name = name
        self.write = open(name, 'w').write
        sys.stderr.write("Writing %s\n" % name)
        if not noheader:
            self.write("""\
/* DO NOT MODIFY THIS FILE!  It was generated by `recode/doc/tables.py'.  */

/* Conversion of files between different charsets and surfaces.
   Copyright © 1999 Free Software Foundation, Inc.
   Contributed by François Pinard <pinard@iro.umontreal.ca>, 1993, 1997.

   The `recode' Library is free software; you can redistribute it and/or
   modify it under the terms of the GNU Library General Public License
   as published by the Free Software Foundation; either version 2 of the
   License, or (at your option) any later version.

   The `recode' Library is distributed in the hope that it will be
   useful, but WITHOUT ANY WARRANTY; without even the implied warranty
   of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
   Library General Public License for more details.

   You should have received a copy of the GNU Library General Public
   License along with the `recode' Library; see the file `COPYING.LIB'.
   If not, write to the Free Software Foundation, Inc., 59 Temple Place -
   Suite 330, Boston, MA 02111-1307, USA.  */
""")

# Main driver.

def main(*arguments):
    global input

    global alias_count
    global charset_ordinal
    global comment
    global discard_charset

    global charname_option
    global explode_option
    global libiconv_option
    global mnemonic_option
    global strip_option
    global libiconv_texinfo_option
    global rfc1345_texinfo_option

    import getopt

    # Argument decoding.
    French_option = 0
    charname_option = 0
    explode_option = 0
    libiconv_option = 0
    mnemonic_option = 0
    strip_option = 0
    libiconv_texinfo_option = 0
    rfc1345_texinfo_option = 0
    options, arguments = getopt.getopt(arguments, 'Felmnpst')
    for option, value in options:
        if option == '-F': French_option = 1
        elif option == '-e': explode_option = 1
        elif option == '-l': libiconv_option = 1
        elif option == '-m': mnemonic_option = 1
        elif option == '-n': charname_option = 1
        elif option == '-p': strip_option = 1
        elif option == '-s': libiconv_texinfo_option = 1
        elif option == '-t': rfc1345_texinfo_option = 1
    if not arguments:
        raise __doc__

    if explode_option:
        produce_explode_init(EXPLODE)
    elif strip_option:
        produce_strip_init(DATA)

    # Prepare to read various tables.

    charset_ordinal = 0
    discard_charset = 0
    alias_count = 0
    comment = ''

    # Read all data tables.

    for name in arguments:
        input = Input(name)
        while 1:
            line = input.readline()
            if not line:
                break
            if line[0] == '\n':
                continue
            if line[0:2] == '/*':
                while string.find(line, '*/') < 0:
                    line = input.readline()
                continue

            if input.begins('DEFENCODING'):
                digest_libiconv()
                break

            if input.begins('#    Name:'):
                digest_unimap()
                break

            if line[0] == '#':
                continue

            if input.begins('escape_char'):
                digest_mnemonics()
                break

            if input.match('Network Working Group +K\. Simonsen$'):
                if charname_option and not French_option:
                    while not input.begins(
                        '   3rd field is the long descriptive'):
                        line = input.readline()
                    digest_rfc1345_names()
                if explode_option or strip_option:
                    while line != '5.  CHARSET TABLES\n':
                        line = input.readline()
                    digest_rfc1345_tables()
                break

            if input.begins(';Titre :'):
                if charname_option and French_option:
                    while input.begins('; SOUSCRIT'):
                        line = input.readline()
                    while not input.match(' *$'):
                        line = input.readline()
                    digest_french_names()
                break

            if line == '&referenceset\n':
                while line != '\n':
                    line = input.readline()
                digest_rfc1345_tables()
                break

            if line == '   Repertoire according to ISO/IEC 10646-1:1993\n':
                while line != '   Plane 000\n':
                    line = input.readline()
                digest_iso10646_def()
                break

            input.die("Data file with unknown contents")

        del input

    if explode_option:
        produce_explode_term()
    elif strip_option:
        produce_strip_term(POOL)
    if charname_option:
        if French_option:
            produce_charname('fr-%s' % CHARNAME)
        else:
            produce_charname(CHARNAME)
    if libiconv_option:
        produce_libiconv(LIBICONV)
    if mnemonic_option:
        produce_mnemonic(RFC1345_MNEMONIC)
    if libiconv_texinfo_option:
        if French_option:
            produce_libiconv_texinfo('fr-%s' % LIBICONV_TEXINFO)
        else:
            produce_libiconv_texinfo(LIBICONV_TEXINFO)
    if rfc1345_texinfo_option:
        if French_option:
            produce_rfc1345_texinfo('fr-%s' % RFC1345_TEXINFO)
        else:
            produce_rfc1345_texinfo(RFC1345_TEXINFO)

# Data readers.

## ----------------------------------------- ##
## Read in Keld's list of 10646 characters.  ##
## ----------------------------------------- ##

def digest_iso10646_def():
    global row, cell

    while 1:
        line = input.readline()
        if not line:
            break
        if line == '\n':
            continue
        if line == ' \n':
            continue                    # happens three times
        if input.begins('   \.\.\.'):
            continue
        if line == '   Presentation forms\n':
            continue
        if input.begins('   naming: first vertical '):
            continue

        match = input.match('   row ([0-9][0-9][0-9])$')
        if match and int(match.group(1)) < 256:
            row = int(match.group(1))
            cell = 0
            continue

        if line == '   cell 00\n':
            cell = 0
            continue

        match = input.match('   cell ([0-9][0-9][0-9])$')
        if match and int(match.group(1)) < 256:
            cell = int(match.group(1))
            continue

        match = input.match('   ([^ ]+)')
        if match:                       # FIXME: $1 n'a pas de sens!
            # s/^   // unless /^   [A-Z][A-Z][A-Z]/;
            if not input.match('   [A-Z][A-Z][A-Z]'):
                continue

        match = input.match('   ([^ ].*)')
        if match:                       # FIXME: $1 n'a pas de sens!
            if cell == 256:
                input.warn("Over 256 cells in row %d", row)
            cell = cell + 1
            continue

        match = (input.match('([^ ])  ([^ ].*)')
                 or input.match('([^ ][^ ]+) ([^ ].*)'))
        if match:                       # FIXME: $2 n'a pas de sens!
            if cell == 256:
                input.warn("Over 256 cells in row %d", row)
            declare_mnemonic(match.group(1), 256*row + cell)
            cell = cell + 1
            continue

        input.warn("Unrecognised line")

## -------------------------- ##
## Read in a mnemonics file.  ##
## -------------------------- ##

def digest_mnemonics():
    while input.readline():
        match = input.match('<([^ \t\n]+)>\t<U(....)>')
        if match:
            mnemonic = re.sub('/(.)', r'\1', match.group(1))
            ucs2 = string.atoi(match.group(2), 16)
            declare_mnemonic(mnemonic, ucs2)

## ---------------------------------------------- ##
## Read in the encodings.def file from libiconv.  ##
## ---------------------------------------------- ##

def digest_libiconv():
    global libiconv_data

    canonical = {}
    for charset in ('Georgian-Academy', 'Georgian-PS', 'MuleLao-1',
                    'Macintosh', 'MacArabic', 'MacCentralEurope',
                    'MacCroatian', 'MacCyrillic', 'MacGreek', 'MacHebrew',
                    'MacIceland', 'MacRoman', 'MacRomania', 'MacThai',
                    'MacTurkish', 'MacUkraine'):
        canonical[string.upper(charset)] = charset

    libiconv_data = []
    comment = None
    line = input.line
    while line:
        if input.begins('DEFENCODING(('):
            aliases = []
            match = re.search('"(.*)"', line)
            if match:
                alias = match.group(1)
                if canonical.has_key(alias):
                    alias = canonical[alias]
                aliases.append(alias)
            line = string.lstrip(input.readline())
            while line != '),\n':
                match = re.search('"(.*)"', line)
                if match:
                    alias = match.group(1)
                    if canonical.has_key(alias):
                        alias = canonical[alias]
                    aliases.append(alias)
                line = string.lstrip(input.readline())
            while line and line != '\n':
                line = input.readline()
            libiconv_data.append((comment, aliases[0], aliases[1:]))
            comment = None
        else:
            if input.begins('/*'):
                comment = line[3:-4]
            elif line != '\n':
                input.warn("Unrecognised line")
            line = input.readline()

## ------------------------------------------------------------------- ##
## Read the text of RFC 1345, saving all character names it declares.  ##
## ------------------------------------------------------------------- ##

# Numeric value of a character, given its mnemonic.
ucs2_map = {}

# Name of character, given its numerical value.
charname_map = {}

# Frequency of each word, then its crypt code.
code_map = {}

# Maximum printable length of a character name.
max_length = 0

def digest_rfc1345_names():
    global max_length

    def read_line():
        skip = 0
        while 1:
            line = input.readline()
            if not line:
                break
            if input.begins('Simonsen'):
                skip = 1
                continue
            if skip:
                if input.begins('RFC 1345'):
                    skip = 0
                continue
            if input.begins('4.  CHARSETS'):
                break
            if line == '\n':
                continue
            if line[0] == ' ':
                return string.lstrip(line[:-1])
        return None

    max_length = 0

    # Read the character descriptions.  Count words in charnames.

    line = read_line()
    while line:
	# Look ahead one line and merge it if it should.

        next = read_line()
        while next:
            match = re.match('             *( .*)', next)
            if not match:
                break
            line = line + match.group(1)
            next = read_line()

	# Separate fields and save needed information.

        match = re.search('([^ ]+) +[0-9a-f]+ +(.*)', line)
        if match:
            mnemo = match.group(1)
            text = string.lower(match.group(2))

            if ucs2_map.has_key(mnemo):
                charname_map[ucs2_map[mnemo]] = text
                if len(text) > max_length:
                    max_length = len(text)
                for word in string.split(text):
                    if code_map.has_key(word):
                        code_map[word] = code_map[word] + 1
                    else:
                        code_map[word] = 1
            elif len(mnemo) <= MAX_MNEMONIC_LENGTH:
                input.warn("No known UCS-2 code for `%s'", mnemo)
        elif not re.search(' +e000', line):
            input.warn("Unrecognised line")

        line = next

def digest_french_names():
    global max_length

    max_length = 0
    ucs = 0x0000

    for text in (
        "nul (nul)",                                        # 0000
        "début d'en-tête (soh)",                            # 0001
        "début de texte (stx)",                             # 0002
        "fin de texte (etx)",                               # 0003
        "fin de transmission (eot)",                        # 0004
        "demande (enq)",                                    # 0005
        "accusé de réception positif (ack)",                # 0006
        "sonnerie (bel)",                                   # 0007
        "espace arrière (bs)",                              # 0008
        "tabulation horizontale (ht)",                      # 0009
        "interligne (lf)",                                  # 000A
        "tabulation verticale (vt)",                        # 000B
        "page suivante (ff)",                               # 000C
        "retour de chariot (cr)",                           # 000D
        "hors code (so)",                                   # 000E
        "en code (si)",                                     # 000F
        "échappement transmission (dle)",                   # 0010
        "commande d'appareil un (dc1)",                     # 0011
        "commande d'appareil deux (dc2)",                   # 0012
        "commande d'appareil trois (dc3)",                  # 0013
        "commande d'appareil quatre (dc4)",                 # 0014
        "accusé de réception négatif (nak)",                # 0015
        "synchronisation (syn)",                            # 0016
        "fin de transmission de bloc (etb)",                # 0017
        "annulation (can)",                                 # 0018
        "fin de support (em)",                              # 0019
        "caractère de substitution (sub)",                  # 001A
        "échappement (esc)",                                # 001B
        "séparateur de fichier (fs)",                       # 001C
        "séparateur de groupe (gs)",                        # 001D
        "séparateur d'article (rs)",                        # 001E
        "séparateur de sous-article (us)",                  # 001F
        ):
        charname_map[ucs] = text
        ucs = ucs + 1
        if len(text) > max_length:
            max_length = len(text)
        for word in string.split(text):
            if code_map.has_key(word):
                code_map[word] = code_map[word] + 1
            else:
                code_map[word] = 1

    ucs = 0x007F
    for text in (
        "suppression (del)",                                # 007F
        "caractère de bourre (pad)",                        # 0080
        "octet supérieur prédéfini (hop)",                  # 0081
        "arrêt permis ici (bph)",                           # 0082
        "aucun arrêt ici (nbh)",                            # 0083
        "index (ind)",                                      # 0084
        "à la ligne (nel)",                                 # 0085
        "début de zone sélectionnée (ssa)",                 # 0086
        "fin de zone sélectionnée (esa)",                   # 0087
        "arrêt de tabulateur horizontal (hts)",             # 0088
        "tabulateur horizontal avec justification (htj)",   # 0089
        "arrêt de tabulateur vertical (vts)",               # 008A
        "interligne partiel vers <= bas (pld)",             # 008B
        "interligne partiel vers <= haut (plu)",            # 008C
        "index inversé (ri)",                               # 008D
        "remplacement unique deux (ss2)",                   # 008E
        "remplacement unique trois (ss3)",                  # 008F
        "chaîne de commande d'appareil (dcs)",              # 0090
        "usage privé un (pu1)",                             # 0091
        "usage privé deux (pu2)",                           # 0092
        "mise en mode transmission (sts)",                  # 0093
        "annulation du caractère précédent (cch)",          # 0094
        "message en attente (mw)",                          # 0095
        "début de zone protégée (sga)",                     # 0096
        "fin de zone protégée (ega)",                       # 0097
        "début de chaîne (sos)",                            # 0098
        "introducteur de caractère graphique unique (sgci)",# 0099
        "introducteur de caractère unique (sci)",           # 009A
        "introducteur de séquence de commande (csi)",       # 009B
        "fin de chaîne (st)",                               # 009C
        "commande de système d'exploitation (osc)",         # 009D
        "message privé (pm)",                               # 009E
        "commande de progiciel (apc)",                      # 009F
        ):
        charname_map[ucs] = text
        ucs = ucs + 1
        if len(text) > max_length:
            max_length = len(text)
        for word in string.split(text):
            if code_map.has_key(word):
                code_map[word] = code_map[word] + 1
            else:
                code_map[word] = 1

    fold_table = range(256)
    for before, after in map(None,
                             'ABCDEFGHIJKLMNOPQRSTUVWXYZÀÂÇÈÉÊÎÏÑÔÖÛ',
                             'abcdefghijklmnopqrstuvwxyzàâçèéêîïñôöû'):
        fold_table[ord(before)] = ord(after)
    folding = string.join(map(chr, fold_table), '')

    while 1:
        line = input.readline()
        if not line:
            break
        if line[-1] == '\n':
            line = line[:-1]
        line = string.rstrip(line)
        input.line = line
        match = input.match('([0-9A-F]{4}) ([^\(]+)( \(.*\))?$')
        if match:
            ucs = string.atoi(match.group(1), 16)
            text = string.translate(match.group(2), folding)

            charname_map[ucs] = re.sub(r' +\*$', '', text, 1)
            if len(match.group(2)) > max_length:
                max_length = len(match.group(2))
            for word in string.split(text):
                if code_map.has_key(word):
                    code_map[word] = code_map[word] + 1
                else:
                    code_map[word] = 1
        else:
            input.warn("Unrecognised line")

## ------------------------------------------------------------ ##
## Read the text of RFC 1345, saving all charsets it declares.  ##
## UCS-2 mnemonics files should have been read in already.      ##
## ------------------------------------------------------------ ##

used_map = {}
table = []

#codedim
#code
#list

declare_alias = []
implied_surface = {}
#hashname

def digest_rfc1345_tables():
    global alias_count
    global aliases
    global charset
    global comment
    global discard_charset
    global remark
    global table

    # Informal canonical order of presentation.
    CHARSET, REM, ALIAS, ESC, BITS, CODE = range(6)

    skip = 0
    while 1:
        line = input.readline()
        if not line:
            break
        if input.begins('Simonsen'):
            skip = 1
            continue
        if skip:
            if input.begins('RFC 1345'):
                skip = 0
            continue
        if line == '\n':
            continue
        if line == 'ACKNOWLEDGEMENTS\n':
            break

        line, count = re.subn('^  ?', '', line)
        if not count:
            continue
        input.line = line

	# Recognize `&charset'.

        match = input.match('&charset (.*)')
        if match:
	    # Before beginning a new charset, process the previous one.
            complete_charset()
            charset = match.group(1)

	    # Prepare for processing a new charset: save the charset
	    # name for further declaration; announce this charset in
	    # the array initialization section; and initialize its
	    # processing.

            sys.stderr.write("  %d) %s\n" % (charset_ordinal + 1, charset))
            status = CHARSET

            comment = '\n/* %s\n' % charset

            hashname = re.sub('[^a-z0-9]', '', string.lower(charset))
            if used_map.has_key(hashname):
                input.warn("Duplicate of %s (discarded)", used_map[hashname])
                discard_charset = 1
                continue
            used_map[hashname] = charset

            alias_count = 0
            table = [NOT_A_CHARACTER] * 256
            codedim = 0
            code = 0
            aliases = []
            remark = []

            match = re.match('(CP|IBM)([0-9]+)$', charset)
            if match:
                implied_surface[match.group(2)] = 'crlf'
                implied_surface['CP' + match.group(2)] = 'crlf'
                implied_surface['IBM' + match.group(2)] = 'crlf'
                declare_alias.append((charset, charset))
                alias_count = alias_count + 1
                continue

            #FIXME:match = re.match('windows-([0-9]+)$', charset)
            #FIXME:if match:
            #FIXME:      implied_surface[match.group(1)] = 'crlf'
            #FIXME:      implied_surface['CP' + match.group(1)] = 'crlf'
            #FIXME:      implied_surface['IBM' + match.group(1)] = 'crlf'
            #FIXME:      declare_alias.append((charset, charset))
            #FIXME:      alias_count = alias_count + 1
            #FIXME:      continue

            if charset in ('macintosh', 'macintosh_ce'):
                implied_surface[charset] = 'cr'
                declare_alias.append((charset, charset))
                alias_count = alias_count + 1
                continue

            continue

	# Recognize other `&' directives.

        match = input.match('&rem (.*)')
        if match and not input.begins('&rem &alias'):
	    # Keld now prefers `&rem' to be allowed everywhere.
	    #if status > REM:
	    #    input.warn("`&rem' out of sequence")
	    #status = REM;

            if rfc1345_texinfo_option:
		# Save remarks for Texinfo.
                text = match.group(1)
                remark.append(text)
            continue

        match = input.match('(&rem )?&alias (.*)')
        if match:
            if status > ALIAS:
                input.warn("`&alias' out of sequence")
            status = ALIAS

	    # Save synonymous charset names for later declarations.

            alias = match.group(2)
            if alias[-1] == ' ':
                input.warn("Spurious trailing whitespace")
                alias = string.rstrip(alias)
            comment = comment + '   %s\n' % alias

            hashname = re.sub('[^a-z0-9]', '', string.lower(alias))
            if used_map.has_key(hashname) and used_map[hashname] != charset:
                input.warn("Duplicate of %s", used_map[hashname])
                continue
            used_map[hashname] = charset

            aliases.append(alias)

            match = re.match('(CP|IBM)([0-9]+)$', alias)
            if match:
                implied_surface[match.group(2)] = 'crlf'
                implied_surface['CP' + match.group(2)] = 'crlf'
                implied_surface['IBM' + match.group(2)] = 'crlf'
            elif alias in ('mac', 'macce'):
                implied_surface[alias] = 'cr'
            declare_alias.append((alias, charset))
            alias_count = alias_count + 1
            continue

        if input.match('&g[0-4]esc'):
            if status > ESC:
                input.warn("`&esc' out of sequence")
            status = ESC
            continue

        match = input.match('&bits ([0-9]+)$')
        if match:
            if status > BITS:
                input.warn("`&bits' out of sequence")
            status = BITS

            if int(match.group(1)) > 8:
                input.warn("`&bits %s' not accepted (charset discarded)",
                           match.group(1))
                discard_charset = 1
            continue

        match = input.match('&code (.*)')
        if match:
            if status > CODE:
                input.warn("`&code' out of sequence")
            status = CODE

	    # Save the code position.

            code = int(match.group(1))
            continue

	# Other lines cause the charset to be discarded.

        match = input.match('&([^ ]+)')
        if match:
            if not discard_charset:
                input.warn("`&%s' not accepted (charset discarded)",
                           match.group(1))
                discard_charset = 1

        if discard_charset:
            continue

	# Save all other tokens into the double table.

        if explode_option or strip_option:
            for token in string.split(line):
                if token == '??':
                    table[code] = NOT_A_CHARACTER
                elif token == '__':
                    table[code] = REPLACEMENT_CHARACTER
                elif ucs2_map.has_key(token):
                    table[code] = ucs2_map[token]
                    if len(token) > codedim:
                        codedim = len(token)
                else:
                    input.warn("Unknown mnemonic for code: %s", token)
                    table[code] = REPLACEMENT_CHARACTER
                code = code + 1

    # Push the last charset out.
    complete_charset()

## ---------------------------------------------------------------- ##
## Read a Unicode map, as found in ftp://ftp.unicode.com/MAPPINGS.  ##
## ---------------------------------------------------------------- ##

def digest_unimap():
    global alias_count
    global aliases
    global charset
    global comment
    global discard_charset
    global remark
    global table

    line = input.line
    match = input.match('# +Name: +([^ ]+) to Unicode table$')
    if match:
        name = string.split(match.group(1))
        charset = name[0]
        del name[0]
        comment = '\n/* %s\n' % charset

        hashname = re.sub('[^a-z0-9]', '', string.lower(charset))
        if used_map[hashname]:
            input.warn("`%s' duplicates `%s' (charset discarded)",
                       hashname, used_map[hashname])
            discard_charset = 1
            return
        used_map[hashname] = charset

        alias_count = 0
        table = [NOT_A_CHARACTER] * 256
        codedim = 0
        code = 0
        aliases = []
        remark = []
    if discard_charset:
        return

    for alias in name:
        comment = comment + '   %s\n' % alias

        hashname = re.sub('[^a-z0-9]', '', string.lower(alias))
        if used_map[hashname] and used_map[hashname] != charset:
            input.warn("`%s' duplicates `%s'", hashname, used_map[hashname])
            continue
        used_map[hashname] = charset

        aliases.append(alias)
        declare_alias.append((alias, charset))
        alias_count = alias_count + 1

    while 1:
        line = input.readline()
        if not line:
            break
        if line == '\n':
            continue
        if line[0] == '#':
            continue
        if input.match('0x([0-9A-F]+)\t\t#UNDEFINED$'):
            continue
        if input.search('\032'):
            # Old MS-DOS C-z !!
            break

        match = input.match('0x([0-9A-F]+)\t0x([0-9A-F]+)\t\#')
        if match:
            table[string.atoi(match.group(1), 16)] \
                                              = string.atoi(match.group(2), 16)
        else:
            input.warn("Unrecognised input line")

    complete_charset()

# Reader services.

## ---------------------------------------------------------------- ##
## Declare a correspondence between a mnemonic and an UCS-2 value.  ##
## ---------------------------------------------------------------- ##

table_length = 0
mnemonic_map = {}

def declare_mnemonic(mnemonic, ucs2):
    global table_length

    if len(mnemonic) > MAX_MNEMONIC_LENGTH:
        return

    if mnemonic_option:
        if mnemonic_map.has_key(ucs2):
            if mnemonic_map[ucs2] != mnemonic:
                input.warn("U+%04X `%s' known as `%s'",
                           ucs2, mnemonic, mnemonic_map[ucs2])
                if len(mnemonic) < len(mnemonic_map[ucs2]):
                    mnemonic_map[ucs2] = mnemonic

        else:
            mnemonic_map[ucs2] = mnemonic
            table_length = table_length + 1

    if charname_option or explode_option or strip_option:
        if ucs2_map.has_key(mnemonic):
            if ucs2_map[mnemonic] != ucs2:
                input.warn("`%s' U+%04X known as U+%04X",
                           mnemonic, ucs2, ucs2_map[mnemonic])
                #FIXME: ??? cell = ucs2_map[mnemonic] - 256*row
        else:
            ucs2_map[mnemonic] = ucs2

## ---------------------------------------------------------- ##
## Print all accumulated information for the charset.  If the ##
## charset should be discarded, adjust tables.                ##
## ---------------------------------------------------------- ##

aliases_map = {}
remark_map = {}
declare_charset = []

def complete_charset():
    global alias_count
    global charset_ordinal
    global comment
    global discard_charset

    if discard_charset:
        while alias_count > 0:
            del declare_alias[-1]
            alias_count = alias_count - 1
        discard_charset = 0
        comment = ''
    if not comment:
        return

    if rfc1345_texinfo_option:

	# Save the documentation.
        aliases.sort()
        aliases_map[charset] = aliases
        remark_map[charset] = remark

    if explode_option:
        write = output.write

	# Make introductory C comments.
        write(comment)
        write('*/\n')

	# Make the table for this charset.
        write('\n')
        write('static const unsigned short data_%d[] =\n' % charset_ordinal)
        write('  {\n')
        for code in range(256):
            if code != table[code]:
                write('    %3d, 0x%.4X, DONE,\n' % (code, table[code]))
        write('    DONE\n')
        write('  };\n')

	# Register the table.
        declare_charset.append(charset)

    if strip_option:
        write = output.write

	# Make introductory C comments.
        write(comment)
        write('*/\n')

	# Make the table for this charset.
        write('\n')
        write('static struct strip_data data_%d =\n' % charset_ordinal)
        write('  {\n')
        write('    ucs2_data_pool,\n')
        write('    {\n')
        count = 0
        for code in range(0, 256, STRIP_SIZE):
            if count % 12 == 0:
                if count != 0:
                    write(',\n')
                write('      ')
            else:
                write(', ')
            write('%4d' % pool_index(table[code:code+STRIP_SIZE]))
            count = count + 1
        write('\n')
        write('    }\n')
        write('  };\n')

	# Register the table.
        declare_charset.append(charset)

    charset_ordinal = charset_ordinal + 1
    comment = ''

## --------------------------------------------------------------- ##
## Return the pool index for strip.  Add to the pool as required.  ##
## --------------------------------------------------------------- ##

def pool_index(strip):
    global strips
    global pool_refs
    global pool_size

    def format(item):
        return '%04X' % item

    pool_refs = pool_refs + 1
    text = string.join (map(format, strip), '')
    if not strip_map.has_key(text):
        strip_map[text] = pool_size
        pool_size = pool_size + STRIP_SIZE
        strips.append(text)
    return strip_map[text]

# Table writers.

## -------------------------------------------- ##
## Write a compressed list of character names.  ##
## -------------------------------------------- ##

def produce_charname(name):
    global output

    output = Output(name)
    write = output.write

    # Establish a mild compression scheme.  Words word[0:singles] will be
    # represented by a single byte running from 1 to singles.  All remaining
    # words will be represented by two bytes, the first one running slowly
    # from singles+1 to 255, the second cycling faster from 1 to 255.

    def presort_word(word):
        return -code_map[word], word

    def postsort_word(pair):
        return pair[1]

    sys.stderr.write('  sorting words...')
    pairs = map(presort_word, code_map.keys())
    pairs.sort()
    words = map(postsort_word, pairs)
    pairs = None
    sys.stderr.write(' %d of them\n' % len(words))

    count = len(words)
    singles = (255 * 255 - count) / 254

    # Transmit a few values for further usage by the C code.

    sys.stderr.write('  sorting names...')
    ucs2_table = charname_map.keys()
    ucs2_table.sort()
    sys.stderr.write(' %d of them\n' % len(ucs2_table))

    write('\n')
    write('#define NUMBER_OF_SINGLES %d\n' % singles)
    write('#define MAX_CHARNAME_LENGTH %d\n' % max_length)
    write('#define NUMBER_OF_CHARNAMES %d\n' % len(ucs2_table))

    # Establish a mild compression scheme (one or two bytes per word).

    sys.stderr.write("  writing words\n")
    write('\n')
    write('static const char *const word[%d] =\n' % count)
    write('  {\n')

    char1 = 1
    char2 = 1

    for counter in range(singles):
        word = words[counter]
        write('    %-28s/* \\%0.3o */\n'
              % ('"%s",' % re.sub('"', r'\"', word), char1))
        code_map[words[counter]] = char1
        char1 = char1 + 1

    for counter in range(singles, count):
        word = words[counter]
        write('    %-28s/* \\%0.3o\\%0.3o */\n'
              % ('"%s",' % re.sub('"', r'\"', word, 1), char1, char2))
        code_map[words[counter]] = 256 * char1 + char2
        if char2 == 255:
            char1 = char1 + 1
            char2 = 1
        else:
            char2 = char2 + 1
    write('  };\n')

    sys.stderr.write("  writing names\n")
    write('\n')
    write('struct charname\n')
    write('  {\n')
    write('    recode_ucs2 code;\n')
    write('    const char *crypted;\n')
    write('  };\n')

    write('\n')
    write('static const struct charname charname[NUMBER_OF_CHARNAMES] =\n')
    write('  {\n')

    for ucs2 in ucs2_table:
        write('    {0x%04X, "' % ucs2)
        for word in string.split(charname_map[ucs2]):
            if code_map.has_key(word):
                code = code_map[word]
                if code < 256:
                    write('\\%0.3o' % code)
                else:
                    write('\\%0.3o\\%0.3o' % (code / 256, code % 256))
            else:
                sys.stderr.write('??? %s\n' % word)
        write('"},\n')

    write('  };\n')
    del output

## ------------------------------- ##
## Write libiconv initialisation.  ##
## ------------------------------- ##

def produce_libiconv(name):
    global output

    output = Output(name)
    write = output.write

    count = 1
    for comment, charset, aliases in libiconv_data:
        count = count + 2 + len(aliases)
    write('\n')
    write("/* This is derived from Bruno Haible's `libiconv' package.  */")
    write('\n')
    write('static const char *iconv_name_list[%d] =\n' % count)
    write('  {\n')
    for comment, charset, aliases in libiconv_data:
        if comment:
            write('\n')
            write('    /* %s.  */\n' % comment)
            write('\n')
        if aliases:
            write('    "%s",\n' % charset)
            for alias in aliases[:-1]:
                write('\t"%s",\n' % alias)
            write('\t"%s", NULL,\n' % aliases[-1])
        else:
            write('    "%s", NULL,\n' % charset)
    write('    NULL\n')
    write('  };\n')

    write('\n')
    write('typedef void *iconv_t;\n')
    write('#ifndef EILSEQ\n')
    write('# define EILSEQ EINVAL\n')
    write('#endif\n')
    write('\n')
    write('#ifdef __cplusplus\n')
    write('extern "C" {\n')
    write('#endif\n')
    write('\n')
    write('iconv_t iconv_open (const char *, const char *);\n')
    write('size_t iconv'
          ' (iconv_t, const char **, size_t *, char **, size_t *);\n')
    write('extern int iconv_close (iconv_t cd);\n')
    write('\n')
    write('#ifdef __cplusplus\n')
    write('}\n')
    write('#endif\n')

    del output

## ------------------------------------------- ##
## Write an UCS-2 to RFC 1345 mnemonic table.  ##
## ------------------------------------------- ##

def produce_mnemonic(name):
    global output
    inverse_map = {}

    output = Output(name)
    write = output.write
    write('\n')
    write('#define TABLE_LENGTH %d\n' % table_length)
    write('#define MAX_MNEMONIC_LENGTH %d\n' % MAX_MNEMONIC_LENGTH)
    write('\n')
    write('struct entry\n')
    write('  {\n')
    write('    recode_ucs2 code;\n')
    write('    const char *rfc1345;\n')
    write('  };\n')

    write('\n')
    write('static const struct entry table[TABLE_LENGTH] =\n')
    write('  {\n')
    count = 0
    indices = mnemonic_map.keys()
    indices.sort()
    for ucs2 in indices:
        text = mnemonic_map[ucs2]
        inverse_map[text] = count
        write('    /* %4d */ {0x%04X, "%s"},\n'
              % (count, ucs2, re.sub(r'([\"])', r'\\\1', text)))
        count = count + 1
    write('  };\n')

    write('\n')
    write('static const unsigned short inverse[TABLE_LENGTH] =\n')
    write('  {')
    count = 0
    keys = inverse_map.keys()
    keys.sort()
    for text in keys:
        if count % 10 == 0:
            if count != 0:
                write(',')
            write('\n    /* %4d */ ' % count)
        else:
            write(', ')
        write('%4d' % inverse_map[text])
        count = count + 1
    write('\n')
    write('  };\n')

    del output

## ------------------------------- ##
## Write the explode source file.  ##
## ------------------------------- ##

def produce_explode_init(name):
    global output

    output = Output(name)
    write = output.write
    write('\n')
    write('#include "common.h"\n')

    # Table fragments will be produced while reading data tables.

def produce_explode_term():

    # Print the collectable initialization function.
    sys.stderr.write("Completing %s\n" % output.name)

    write = output.write
    write('\n')
    write('bool\n')
    write('module_explodes (struct recode_outer *outer)\n')
    write('{\n')
    count = 0
    while declare_charset:
        write('  if (!declare_explode_data (outer, &data_%d, "%s"))\n'
              % (count, declare_charset[0]))
        write('    return false;\n')
        del declare_charset[0]
        count = count + 1
    write('\n')
    while declare_alias:
	write('  if (!declare_alias (outer, "%s", "%s"))\n' % declare_alias[0])
        write('    return false;\n')
        del declare_alias[0]
    write('\n')
    write('  return true;\n')
    write('}\n')

    del output

## --------------------------------- ##
## Write the pool and index tables.  ##
## --------------------------------- ##

def produce_strip_init(name):
    global output
    global pool_refs
    global pool_size
    global strips
    global strip_map

    # Prepare the production of tables.
    pool_size = 0
    pool_refs = 0
    strip_map = {}
    strips = []

    output = Output(name)
    write = output.write
    write('\n')
    write('#include \"common.h\"\n')

    # Table fragments will be produced while reading data tables.

def produce_strip_term(pool_name):
    global output

    # Give memory statistics.
    sys.stderr.write('Table memory = %d bytes (pool %d, refs %d)\n'
                     % (pool_size * 2 + pool_refs * 2,
                        pool_size * 2,
                        pool_refs * 2))

    # Print the collectable initialization function.
    sys.stderr.write("Completing %s\n" % output.name)
    write = output.write

    write('\n')
    write('bool\n')
    write('module_strips (struct recode_outer *outer)\n')
    write('{\n')
    write('  RECODE_SYMBOL symbol;\n')
    write('\n')
    count = 0
    while declare_charset:
        write('  if (!declare_strip_data (outer, &data_%d, "%s"))\n'
              % (count, declare_charset[0]))
        write('    return false;\n')
        del declare_charset[0]
        count = count + 1
    write('\n')
    while declare_alias:
        alias, charset = declare_alias[0]
        if implied_surface.has_key(alias):
            write('  if (symbol = declare_alias (outer, "%s", "%s"), !symbol)\n'
                  % declare_alias[0])
	    write('    return false;\n')
	    write('  if (!declare_implied_surface (outer, symbol, outer->%s_surface))\n'
                  % implied_surface[alias])
	    write('    return false;\n')
        else:
	    write('  if (!declare_alias (outer, "%s", "%s"))\n'
                  % declare_alias[0])
	    write('    return false;\n')
        del declare_alias[0]
    write('\n')
    write('  return true;\n')
    write('}\n')
    del output

    # Write the pool file.

    output = Output(pool_name)
    write = output.write
    write('\n')
    write('#include \"common.h\"\n')
    write('\n')
    write('const recode_ucs2 ucs2_data_pool[%d] =\n' % pool_size)
    write('  {')
    count = 0
    for strip in strips:
        for pos in range(0, STRIP_SIZE * 4, 4):
            if count % 8 == 0:
                if count != 0:
                    write(',')
                write('\n    /* %4d */ ' % count)
            else:
                write(', ')
            write('0x' + strip[pos:pos+4])
            count = count + 1
    write('\n')
    write('  };\n')

    del output

## ------------------------------- ##
## Write the documentation files.  ##
## ------------------------------- ##

def produce_libiconv_texinfo(name):
    global output

    output = Output(name, noheader=1)
    write = output.write
    write('\n')
    write('@itemize @bullet\n')
    block = None
    for comment, charset, aliases in libiconv_data:
        if not block and not comment:
            comment = 'General character sets'
        if comment:
            if block:
                write('@end table\n')
                write('\n')
            write('@item %s\n' % comment)
            write('@table @code\n')
            block = comment
        else:
            write('\n')
        write('@item %s\n' % charset)
        if aliases:
            write('@tindex %s@r{, aliases}\n'
                  % re.sub(':([0-9]+)', r'(\1)', charset))
            for alias in aliases:
                write('@tindex %s\n' % re.sub(':([0-9]+)', r'(\1)', alias))
            if len(aliases) == 1:
                write('@code{%s} is an alias for this charset.\n' % aliases[0])
            else:
                write('@code{%s} and @code{%s} are aliases for this charset.\n'
                      % (string.join(aliases[:-1], '}, @code{'), aliases[-1]))
        else:
            write('@tindex %s\n' % re.sub(':([0-9]+)', r'(\1)', charset))
    write('@end table\n')
    write('@end itemize\n')

    del output

def produce_rfc1345_texinfo(name):
    global output

    output = Output(name, noheader=1)
    write = output.write

    charsets = remark_map.keys()
    charsets.sort()
    for charset in charsets:
        write('\n')
        write('@item %s\n' % charset)
	write('@tindex %s@r{, aliases and source}\n'
              % re.sub(':([0-9]+)', r'(\1)', charset))
        aliases = aliases_map[charset]
        if aliases:
            if len(aliases) == 1:
                if aliases[0]:                # FIXME: pourquoi parfois vide ??
                    write('@tindex %s\n'
                          % re.sub(':([0-9]+)', r'(\1)', aliases[0]))
                    write('@code{%s} is an alias for this charset.\n'
                          % aliases[0])
            else:
                for alias in aliases:
                    write('@tindex %s\n'
                          % re.sub(':([0-9]+)', r'(\1)', alias))
                write('@code{%s} and @code{%s} are aliases for this charset.\n'
                      % (string.join(aliases[:-1], '}, @code{'), aliases[-1]))
        for line in remark_map[charset]:
            if line[0] in string.lowercase:
                line = string.upper(line[0]) + line[1:]
            write(string.replace(line, '@', '@@'))
            if line[-1] != '.':
                write('.')
            write('\n')

    del output

if __name__ == '__main__':
    apply(main, tuple(sys.argv[1:]))
